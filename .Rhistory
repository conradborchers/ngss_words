unlist(er)
na.omit(er)
tail(er)
tail(er, 200)
tail(er, 500)
is.na(er)
library(tidyverse)
library(tidytext)
collapseOR(words)
words
aa = c("i like science", "hello")
grep(collapseOR(words), aa)
c(1, 4, 7)
1:7 c(1, 4, 7)
1:7 == c(1, 4, 7)
words <- list("thank you", "thank", "you")
test <- add_to_df(words, tweets_dl[1:100,]) # takes ~ 10 s per string for whole data set
test[,(ncol(test)-2):ncol(test)]
swords
rm(list=ls())
library(magrittr)
library(stopwords)
library(stringr)
library(rlist)
load("NGSSchat_sentiment_states_revised.rda")
words <- strsplit(tweets_dl$text, split=" ") %>% unlist() %>% as.character()
swords <- stopwords(language = "en", source = "nltk")
swords <- c(swords, stopwords(language = "en",source = "smart"))
swords <- c(swords, stopwords(language = "en",source = "snowball"))
swords <- c(swords, stopwords(language = "en",source = "stopwords-iso"))
swords <- unique(swords)
swords
tweets_dl$text %>% head()
rm(list=ls())
library(magrittr)
library(stopwords)
library(stringr)
library(rlist)
load("NGSSchat_sentiment_states_revised.rda")
words <- strsplit(tweets_dl$text, split=" ") %>% unlist() %>% as.character()
words <- gsub('[[:punct:] ]+',' ', words)
words
tolower("MA")
# Setup
rm(list=ls())
library(magrittr)
library(stopwords)
library(stringr)
library(rlist)
load("NGSSchat_sentiment_states_revised.rda")
words <- strsplit(tweets_dl$text, split=" ") %>% unlist() %>% as.character()
words <- gsub('[[:punct:] ]+','', words) # remove punctuation
words <- tolower(words)                  # remove caps
swords <- stopwords(language = "en", source = "nltk")
swords <- c(swords, stopwords(language = "en",source = "smart"))
swords <- c(swords, stopwords(language = "en",source = "snowball"))
swords <- c(swords, stopwords(language = "en",source = "stopwords-iso"))
swords <- unique(swords)
words <- words[-which(words %in% swords)]
ind <- grep("^#", words)
ind <- c(ind, grep("^@", words))
words <- words[-ind]
common_words <- sort(table(words), decreasing=T)
head(common_words)
common_words <- as.data.frame(common_words)
common_words <- common_words[common_words$Freq >= 100,]
write.csv(common_words, "common_words.csv")
rm(list=ls())
library(magrittr)
library(stopwords)
library(stringr)
library(rlist)
load("NGSSchat_sentiment_states_revised.rda")
words <- strsplit(tweets_dl$text, split=" ") %>% unlist() %>% as.character()
words <- gsub('[[:punct:] ]+','', words) # remove punctuation
words <- tolower(words)                  # remove caps
words
swords <- stopwords(language = "en", source = "nltk")
swords <- c(swords, stopwords(language = "en",source = "smart"))
swords <- c(swords, stopwords(language = "en",source = "snowball"))
swords <- c(swords, stopwords(language = "en",source = "stopwords-iso"))
swords <- unique(swords)
words <- words[-which(words %in% swords)]
words
ind <- grep("^#", words)
ind <- c(ind, grep("^@", words))
ind
common_words <- sort(table(words), decreasing=T)
head(common_words)
common_words <- as.data.frame(common_words)
common_words <- common_words[common_words$Freq >= 100,]
write.csv(common_words, "common_words.csv")
grep("ed$", words)
grep("ed$", "jaded")
grep("ed$", "ed")
grep(".ed$", "ed")
grep(".ed$", "jaded")
ind <- grep(".ed$", words)
length(ind)
ind <- grep("ed$", words)
length(ind)
words
words[2]
words[2][-2]
words[2][1]
words[2]substr(words[i], 1, nchar(words[i]) - 2)
substr(words[1], 1, nchar(words[1]) - 2)
words[1]
rm(list=ls())
library(magrittr)
library(stopwords)
library(stringr)
library(rlist)
load("NGSSchat_sentiment_states_revised.rda")
words <- strsplit(tweets_dl$text, split=" ") %>% unlist() %>% as.character()
words <- gsub('[[:punct:] ]+','', words) # remove punctuation
words <- tolower(words)                  # remove caps
swords <- stopwords(language = "en", source = "nltk")
swords <- c(swords, stopwords(language = "en",source = "smart"))
swords <- c(swords, stopwords(language = "en",source = "snowball"))
swords <- c(swords, stopwords(language = "en",source = "stopwords-iso"))
swords <- unique(swords)
words <- words[-which(words %in% swords)]
ind <- grep(".ed$", words)
for (i in 1:length(words)){
if (i %in% ind){
words[i] <- substr(words[i], 1, nchar(words[i]) - 2)
}
}
3+3
ind <- grep(".ing$", words)
for (i in 1:length(words[1:100])){
if (i %in% ind){
words[i] <- substr(words[i], 1, nchar(words[i]) - 3)
}
}
common_words <- sort(table(words), decreasing=T)
head(common_words)
common_words <- as.data.frame(common_words)
common_words <- common_words[common_words$Freq >= 100,]
write.csv(common_words, "common_words.csv")
rm(list=ls())
library(magrittr)
library(stopwords)
library(stringr)
library(rlist)
load("NGSSchat_sentiment_states_revised.rda")
words <- strsplit(tweets_dl$text, split=" ") %>% unlist() %>% as.character()
words <- gsub('[[:punct:] ]+','', words) # remove punctuation
words <- tolower(words)                  # remove caps
swords <- stopwords(language = "en", source = "nltk")
swords <- c(swords, stopwords(language = "en",source = "smart"))
swords <- c(swords, stopwords(language = "en",source = "snowball"))
swords <- c(swords, stopwords(language = "en",source = "stopwords-iso"))
swords <- unique(swords)
words <- words[-which(words %in% swords)]
ind <- grep(".ed$", words)
for (i in 1:length(words)){
if (i %in% ind){
words[i] <- substr(words[i], 1, nchar(words[i]) - 2)
}
}
3+3
ind <- grep(".ing$", words)
for (i in 1:length(words)){
if (i %in% ind){
words[i] <- substr(words[i], 1, nchar(words[i]) - 3)
}
}
3+3
common_words <- sort(table(words), decreasing=T)
head(common_words)
common_words <- as.data.frame(common_words)
common_words <- common_words[common_words$Freq >= 100,]
write.csv(common_words, "common_words.csv")
rm(list=ls())
library(magrittr)
library(stopwords)
library(stringr)
library(rlist)
load("NGSSchat_sentiment_states_revised.rda")
words <- strsplit(tweets_dl$text, split=" ") %>% unlist() %>% as.character()
ind <- grep("^#", words)          # Remove hashtags
ind <- c(ind, grep("^@", words))  # Remove tagged usernames
words <- words[-ind]
words <- gsub('[[:punct:] ]+','', words) # remove punctuation
words <- tolower(words)                  # remove caps
swords <- stopwords(language = "en", source = "nltk")
swords <- c(swords, stopwords(language = "en",source = "smart"))
swords <- c(swords, stopwords(language = "en",source = "snowball"))
swords <- c(swords, stopwords(language = "en",source = "stopwords-iso"))
swords <- unique(swords)
words <- words[-which(words %in% swords)]
common_words <- sort(table(words), decreasing=T)
head(common_words)
common_words <- as.data.frame(common_words)
common_words <- common_words[common_words$Freq >= 100,]
write.csv(common_words, "common_words.csv")
rm(list=ls())
setwd("C:/Users/conra/Documents/GitHub/ngss_words")
pakete <- list("stringr", "rlist", "magrittr")
for (paket in pakete){
if(eval(bquote(!require(.(paket))))){
install.packages(paket);
eval(bquote(require(.(paket))))
}}
source("functions.R")
load("NGSSchat_sentiment_states_revised.rda")
tweets <- tweets_dl$text
tweets <- gsub('[[:punct:] ]+','', tweets) # remove punctuation
tweets <- tolower(tweets)                  # remove caps
words <- list("thank you", "thank", "you")
test <- add_to_df(words, tweets_dl[1:100,]) # takes ~ 10 s per string for whole data set
test[,(ncol(test)-2):ncol(test)]
sum(test$thank == 1)
sum(test$you == 1)
sum(test$thank.you == 1)
# Setup
rm(list=ls())
setwd("C:/Users/conra/Documents/GitHub/ngss_words")
pakete <- list("stringr", "rlist", "magrittr")
for (paket in pakete){
if(eval(bquote(!require(.(paket))))){
install.packages(paket);
eval(bquote(require(.(paket))))
}}
source("functions.R")
load("NGSSchat_sentiment_states_revised.rda")
tweets <- tweets_dl$text
tweets <- gsub('[[:punct:] ]+','', tweets) # remove punctuation
tweets <- tolower(tweets)                  # remove caps
# Testing
# Search whether tweets contain "thank you", "thank",
# or "you" and add 0;1 boolean variable to data frame
words <- list("thank you", "thank", "you")
test <- add_to_df(words, tweets_dl[1:100,]) # takes ~ 10 s per string for whole data set
test[,(ncol(test)-2):ncol(test)]
# Descriptives; n
sum(test$thank == 1)
sum(test$you == 1)
sum(test$thank.you == 1)
# Test "any"
words <- list("science", "math", "physics")
test <- add_to_df_category(words, tweets_dl[1:100,], "STEM")
er <- add_any(words, tweets_dl, category_name = "STEM")
tweets
rm(list=ls())
setwd("C:/Users/conra/Documents/GitHub/ngss_words")
pakete <- list("stringr", "rlist", "magrittr")
for (paket in pakete){
if(eval(bquote(!require(.(paket))))){
install.packages(paket);
eval(bquote(require(.(paket))))
}}
source("functions.R")
load("NGSSchat_sentiment_states_revised.rda")
tweets <- tweets_dl$text
tweets <- gsub('[[:punct:] ]+','', tweets) # remove punctuation
tweets
tweets <- tweets_dl$text
tweets <- gsub('[[:punct:] ]+',' ', tweets) # remove punctuation
tweets <- tolower(tweets)                  # remove caps
tweets
words <- list("thank you", "thank", "you")
test <- add_to_df(words, tweets_dl[1:100,]) # takes ~ 10 s per string for whole data set
q
qu
rm(list=ls())
setwd("C:/Users/conra/Documents/GitHub/ngss_words")
pakete <- list("stringr", "rlist", "magrittr")
for (paket in pakete){
if(eval(bquote(!require(.(paket))))){
install.packages(paket);
eval(bquote(require(.(paket))))
}}
source("functions.R")
load("NGSSchat_sentiment_states_revised.rda")
tweets <- tweets_dl$text
tweets <- gsub('[[:punct:] ]+',' ', tweets) # remove punctuation
tweets <- tolower(tweets)                  # remove caps
words <- list("thank you", "thank", "you")
test <- add_to_df(words, tweets_dl[1:100,]) # takes ~ 10 s per string for whole data set
words <- list("thank you", "thank", "you")
test <- add_to_df(words, tweets_dl[1:100,]) # takes ~ 10 s per string for whole data set
test[,(ncol(test)-2):ncol(test)]
source("functions.R")
words <- list("thank you", "thank", "you")
test <- add_to_df(words, tweets_dl[1:100,]) # takes ~ 10 s per string for whole data set
test[,(ncol(test)-2):ncol(test)]
words <- list("science", "math", "physics")
test <- add_to_df_category(words, tweets_dl[1:100,], "STEM")
words <- list("science", "math", "physics")
test <- add_to_df_category(words, tweets_dl[1:100,], "STEM")
er <- add_any(words, tweets_dl, category_name = "STEM")
words <- list("science", "math", "physics")
test <- add_to_df_category(words, tweets_dl[1:100,], "STEM")
er <- add_any(words, tweets_dl, category_name = "STEM")
any(words, tweets)
collapseOR(words)
words
collapseOR(words)
collapseOR(words=words)
collapseOR(list("hello", "world"))
source("functions.R")
collapseOR
collapseOR(words)
words <- list("science", "math", "physics")
test <- add_to_df_category(words, tweets_dl[1:100,], "STEM")
er <- add_any(words, tweets_dl, category_name = "STEM")
collapseOR(words)
any(words, tweets)
aa = any(words, tweets)
convert2bool(aa, tweets_dl)
rm(list=ls())
setwd("C:/Users/conra/Documents/GitHub/ngss_words")
pakete <- list("stringr", "rlist", "magrittr")
for (paket in pakete){
if(eval(bquote(!require(.(paket))))){
install.packages(paket);
eval(bquote(require(.(paket))))
}}
source("functions.R")
load("NGSSchat_sentiment_states_revised.rda")
tweets <- tweets_dl$text
tweets <- gsub('[[:punct:] ]+',' ', tweets) # remove punctuation
tweets <- tolower(tweets)                  # remove caps
words <- list("thank you", "thank", "you")
test <- add_to_df(words, tweets_dl[1:100,]) # takes ~ 10 s per string for whole data set
test[,(ncol(test)-2):ncol(test)]
sum(test$thank == 1)
sum(test$you == 1)
sum(test$thank.you == 1)
words <- list("science", "math", "physics")
add_any(words, tweets, tweets_dl, "STEM")
add_any(words, tweets[1:100], tweets_dl[1:100,], "STEM")
rm(list=ls())
setwd("C:/Users/conra/Documents/GitHub/ngss_words")
pakete <- list("stringr", "rlist", "magrittr")
for (paket in pakete){
if(eval(bquote(!require(.(paket))))){
install.packages(paket);
eval(bquote(require(.(paket))))
}}
source("functions.R")
load("NGSSchat_sentiment_states_revised.rda")
tweets <- tweets_dl$text
tweets <- gsub('[[:punct:] ]+',' ', tweets) # remove punctuation
tweets <- tolower(tweets)                  # remove caps
words <- list("thank you", "thank", "you")
test <- add_to_df(words, tweets_dl[1:100,]) # takes ~ 10 s per string for whole data set
test[,(ncol(test)-2):ncol(test)]
sum(test$thank == 1)
sum(test$you == 1)
sum(test$thank.you == 1)
words <- list("science", "math", "physics")
add_any(words, tweets[1:100], tweets_dl[1:100,], "STEM")
add_any(words, tweets[1:100], tweets_dl[1:100,])
test <- add_to_df_category(words, tweets[1:100], tweets_dl[1:100,], "STEM")
test
sum(test$STEM == 1)
words <- list("science", "math", "physics")
add_any(words, tweets[1:100], tweets_dl[1:100,])
test <- add_to_df_category(words, tweets[1:100], tweets_dl[1:100,], "STEM")
sum(test$STEM == 1)
asking_qs <- list(
"defining problems",
"asking questions for science",
"asking science questions",
"asking sci questions",
"inquiry",
"problem definition",
"engineering questions "
)
models <- list(
"developing models",
"using models",
"designing models",
"constructing models",
"implementing models",
"crafting models"
)
investigations <- list(
"planning investigation*",
"plan investigation*",
"carrying out investigation*",
"science investigation*",
"sci investigation*",
"planning inquiry",
"doing inquiry",
"group investigation*",
"group inquiry"
)
ana_data <- list(
"data analysis",
"analyzing data",
"analyze data",
"data interpretation",
"interpreting data",
"data analytics"
)
math_comp <- list(
"computational thinking",
"using mathematics",
"use mathematics",
"think computationally",
"thinking computationally",
"mathematical thinking",
"think mathematically",
"abstract thinking",
"symbolic abstraction",
"mathematical abstraction"
)
expl_sol <- list(
"constructing explanations",
"construct explanations",
"craft explanations",
"find explanations",
"finding explanations",
"designing explanations",
"arriving at explanations",
"designing solutions",
"crafting solutions",
"finding solutions",
"find solutions",
"arriving at solutions",
"constructing solutions"
)
argument <- list(
"engaging in argument from evidence",
"discussing result*",
"discuss result*",
"discussing evidence",
"discuss evidence",
"argument about result*",
"argument about evidence",
"argument on result*",
"argument on evidence",
"argue over result*",
"argue over evidence"
)
information <- list(
"obtaining info*",
"obtaine info*",
"evaluating info*",
"evaluate info*",
"communicating info*",
"communicate info*",
"obtaining intel",
"obtaine intel",
"evaluating intel",
"evaluate intel",
"communicating intel",
"communicate intel",
"presenting info*",
"present info*",
"presenting intel",
"present intel",
"communicating result*",
"communicate result*"
)
source("wordlist.R")
test <- add_to_df_category(ana_data, tweets[1:100], tweets_dl[1:100,], "STEM")
test
test$ana_data == 1
test$ana_data
test$STEM
tweets_dl <- add_to_df_category(ana_data, tweets, tweets_dl, "ana_data")
tweets_dl
tweets_dl$ana_data
tweets_dl$ana_data == 0
sum(tweets_dl$ana_data == 1=
sum(tweets_dl$ana_data == 1)
rm(list=ls())
setwd("C:/Users/conra/Documents/GitHub/ngss_words")
pakete <- list("stringr", "rlist", "magrittr")
for (paket in pakete){
if(eval(bquote(!require(.(paket))))){
install.packages(paket);
eval(bquote(require(.(paket))))
}}
source("functions.R")
load("NGSSchat_sentiment_states_revised.rda")
tweets <- tweets_dl$text
tweets <- gsub('[[:punct:] ]+',' ', tweets) # remove punctuation
tweets <- tolower(tweets)                   # remove caps
words <- list("thank you", "thank", "you")
test <- add_to_df(words, tweets_dl[1:100,]) # takes ~ 10 s per string for whole data set
test[,(ncol(test)-2):ncol(test)]
sum(test$thank == 1)
sum(test$you == 1)
sum(test$thank.you == 1)
words <- list("science", "math", "physics")
add_any(words, tweets[1:100], tweets_dl[1:100,])
test <- add_to_df_category(words, tweets[1:100], tweets_dl[1:100,], "STEM")
sum(test$STEM == 1)
source("wordlist.R")
tweets_dl <- add_to_df_category(asking_qs, tweets, tweets_dl, "asking_qs")
tweets_dl <- add_to_df_category(models, tweets, tweets_dl, "models")
tweets_dl <- add_to_df_category(investigations, tweets, tweets_dl, "investigations")
tweets_dl <- add_to_df_category(ana_data, tweets, tweets_dl, "investigations")
tweets_dl <- add_to_df_category(math_comp, tweets, tweets_dl, "expl_sol")
tweets_dl <- add_to_df_category(expl_sol, tweets, tweets_dl, "expl_sol")
tweets_dl <- add_to_df_category(argument, tweets, tweets_dl, "argument")
tweets_dl <- add_to_df_category(information, tweets, tweets_dl, "information")
sum(tweets_dl$asking_qs == 1)
sum(tweets_dl$models == 1)
sum(tweets_dl$investigations == 1)
sum(tweets_dl$ana_data == 1)
sum(tweets_dl$math_comp == 1)
sum(tweets_dl$expl_sol == 1)
sum(tweets_dl$argument == 1)
sum(tweets_dl$information == 1)
